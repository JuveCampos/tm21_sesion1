amlo_limpio$text
amlo_limpio <- amlo %>%
mutate(text = str_remove_all(text, "¬"),
text = str_remove_all(text, "\\n"),
text = str_extract_all(text, "^[a-zA-Z]+$"))
amlo_limpio$text
amlo_limpio <- amlo %>%
mutate(text = str_remove_all(text, "¬"),
text = str_remove_all(text, "\\n"),
text = str_extract_all(text, "^[a-zA-Záéíóú]+$"))
amlo_limpio$text
amlo_limpio <- amlo %>%
mutate(text = str_remove_all(text, "¬"),
text = str_remove_all(text, "\\n"),
text = str_extract_all(text, "^[a-zA-ZáéíóúÁÉÍÓÚ]+$"))
amlo_limpio$text
amlo_limpio <- amlo %>%
mutate(text = str_remove_all(text, "¬"),
text = str_remove_all(text, "\\n"),
text = str_extract_all(text, "[a-z]+"))
amlo_limpio$text
amlo_limpio <- amlo %>%
mutate(text = str_remove_all(text, "¬"),
text = str_remove_all(text, "\\n"),
text = str_extract_all(text, "[A-Za-z]+"))
amlo_limpio$text
amlo_limpio <- amlo %>%
mutate(text = str_remove_all(text, "¬"),
text = str_remove_all(text, "\\n"),
text = str_remove_all(text, "[^a-zA-Z0-9]"))
amlo_limpio$text
amlo_limpio <- amlo %>%
mutate(text = str_remove_all(text, "¬"),
text = str_remove_all(text, "\\n"),
text = str_remove_all(text, "[^a-zA-Z0-9 ]"))
amlo_limpio$text
amlo_limpio <- amlo %>%
mutate(text = str_remove_all(text, "¬"),
text = str_remove_all(text, "\\n"),
text = str_remove_all(text, "[^a-zA-ZáéíóúAÉÍÓÚ ]"))
amlo_limpio$text
amlo_limpio$text
amlo <- readtext("01_datos/politica/Hacia una economía moral (Spanish Edition) by Andrés Manuel López Obrador [López Obrador, Andrés Manuel] (z-lib.org).pdf")
amlo <- readtext("01_datos/politica/Hacia una economía moral (Spanish Edition) by Andrés Manuel López Obrador [López Obrador, Andrés Manuel] (z-lib.org).pdf")
amlo <- readtext("01_datos/politica/Hacia una economía moral.pdf")
amlo <- readtext("01_datos/politica/Hacia una economía moral.pdf")
fecal <- epub("01_datos/politica/Felipe Calderón Hinojosa - Decisiones difíciles-Penguin Random House Grupo Editorial México (2020) (1).epub")
fecal <- epub("01_datos/politica/Decisiones difíciles.epub")
AMLO
amlo
amlo_limpio <- amlo %>%
mutate(text = str_remove_all(text, "¬"),
text = str_remove_all(text, "\\n"),
text = str_remove_all(text, "[^a-zA-ZáéíóúAÉÍÓÚ ]"))
amlo_limpio
amlo_limpio$text
amlo$text
amlo_limpio <- amlo %>%
mutate(text = str_replace_all(text, "\\n", " ")))
amlo_limpio <- amlo %>%
mutate(text = str_replace_all(text, "\\n", " "))
amlo_limpio$text
amlo_limpio <- amlo %>%
mutate(text = str_replace_all(text, "\\n", " "),
text = str_remove_all(text, "[^a-zA-ZáéíóúAÉÍÓÚ ]"))
amlo_limpio$text
amlo_limpio <- amlo %>%
mutate(text = str_replace_all(text, "\\n", " "),
text = str_remove_all(text, "[^a-zA-ZáéíóúAÉÍÓÚ ]"),
text = str_squish(text))
amlo_limpio$text
pacman::p_load(tidyverse,
guternbergr,
readtext,
epubr,
here)
pacman::p_load(tidyverse,
gutenbergr,
readtext,
epubr,
here)
pacman::p_load(tidyverse,
gutenbergr,
readtext,
epubr,
here)
amlo_limpio$text
fecal.txt
fecal.txt <- fecal$data[[1]]
fecal.txt
fecal.txt <- fecal %>%
mutate(text = str_replace_all(text, "\\n", " "),
text = str_remove_all(text, "[^a-zA-ZáéíóúAÉÍÓÚ ]"),
text = str_squish(text))
fecal_limpio <- fecal.txt %>%
mutate(text = str_replace_all(text, "\\n", " "),
text = str_remove_all(text, "[^a-zA-ZáéíóúAÉÍÓÚ ]"),
text = str_squish(text))
clean_text <- function(data, vars) {
data %>%
mutate({{ vars }} = str_replace_all({{ vars }}, "\\n", " "),
{{ vars }} = str_remove_all({{ vars }}, "[^a-zA-ZáéíóúAÉÍÓÚ ]"),
{{ vars }} = str_squish({{ vars }}))
}
data %>%
mutate({{ vars }} = str_replace_all({{ vars }}, "\\n", " "),
{{ vars }} = str_remove_all({{ vars }}, "[^a-zA-ZáéíóúAÉÍÓÚ ]"),
{{ vars }} = str_squish({{ vars }}))
clean_text <- function(data, vars) {
data %>%
mutate({{ vars }} = str_replace_all({{ vars }}, "\\n", " "),
{{ vars }} = str_remove_all({{ vars }}, "[^a-zA-ZáéíóúAÉÍÓÚ ]"),
{{ vars }} = str_squish({{ vars }}))
}
data %>%
mutate({{ vars }} = str_replace_all({{ vars }}, "\\n", " "))
summarise_mean <- function(data, vars) {
data %>% summarise(n = n(), across({{ vars }}, mean))
}
clean_text <- function(data, vars) {
data %>%
mutate({{ vars }} = str_replace_all({{ vars }}, "\\n", " "))
}
testfunc <- function(df, new_col) {
df <- df %>%
mutate(!!new_col_name = str_remove_all(!!new_col, "[^a-zA-ZáéíóúAÉÍÓÚ ]")
}
df <- df %>% mutate(!!new_col_name := str_remove_all(!!new_col, "[^a-zA-ZáéíóúAÉÍÓÚ ]")
}
mtcars %>%
group_by(cyl) %>%
summarise_mean(where(is.numeric))
testfunc <- function(df, new_col) {
df <- df %>% mutate(!!new_col_name := str_remove_all(!!new_col, "[^a-zA-ZáéíóúAÉÍÓÚ ]")
}
testfunc <- function(df, new_col) { df <- df %>% mutate(!!new_col_name := str_remove_all(!!new_col, "[^a-zA-ZáéíóúAÉÍÓÚ ]")}
testfunc <- function(df, new_col) {
df <- df %>% mutate(!!new_col_name := str_remove_all(!!new_col, "[^a-zA-ZáéíóúAÉÍÓÚ ]"))
}
fecal.txt %>%
mutate(text = testfunc(text))
textfunc
fecal.txt %>%
mutate(text = testfunc(text))
testfunc(fecal.txt, text)
names(fecal.txt)
testfunc <- function(df, text) {
df %>%
mutate(!! (text) := !!str_remove_all(text, "[^a-zA-ZáéíóúAÉÍÓÚ ]"))
}
testfunc(fecal.txt, text)
df %>%
mutate(!! (text) := str_remove_all(!!text, "[^a-zA-ZáéíóúAÉÍÓÚ ]"))
testfunc <- function(df, text) {
df %>%
mutate(!! (text) := str_remove_all(!!text, "[^a-zA-ZáéíóúAÉÍÓÚ ]"))
}
testfunc(fecal.txt, text)
df %>%
mutate(!!text := str_remove_all(!!text, "[^a-zA-ZáéíóúAÉÍÓÚ ]"))
testfunc <- function(df, text) {
df %>%
mutate(!!text := str_remove_all(!!text, "[^a-zA-ZáéíóúAÉÍÓÚ ]"))
}
testfunc(fecal.txt, text)
df %>%
mutate(!!text := str_remove_all(!! text, "[^a-zA-ZáéíóúAÉÍÓÚ ]"))
df %>%
mutate(!!text := str_remove_all(!! text, "[^a-zA-ZáéíóúAÉÍÓÚ ]"))
}
df %>%
mutate(!!text := str_remove_all(!! text, "[^a-zA-ZáéíóúAÉÍÓÚ ]"))
}
testfunc <- function(df, text) {
df %>%
mutate(!!text := str_remove_all(!! text, "[^a-zA-ZáéíóúAÉÍÓÚ ]"))
}
testfunc(fecal.txt, text)
f = function(df, new_col_name) {
df %>% mutate(new_col_name = str_remove_all(new_col_name, "[^a-zA-ZáéíóúAÉÍÓÚ ]"))
}
f(fecal.txt, text)
class(fecal.txt$text)
f = function(df, new_col_name) {
df %>% mutate(new_col_name = str_remove_all(as.character(new_col_name), "[^a-zA-ZáéíóúAÉÍÓÚ ]"))
}
f(fecal.txt, text)
multifun <- function(dataf, vari){
dataf <- mutate(dataf, vari = (vari, "[^a-zA-ZáéíóúAÉÍÓÚ ]"));
return(dataf)
}
multifun <- function(dataf, vari){
dataf <- mutate(dataf, vari = (vari, "[^a-zA-ZáéíóúAÉÍÓÚ ]"));
return(dataf)
}
multifun <- function(dataf, vari){
dataf <- mutate(dataf, newcol = (vari, "[^a-zA-ZáéíóúAÉÍÓÚ ]"));
return(dataf)
}
multifun <- function(dataf, vari){
dataf <- mutate(dataf, newcol = str_remove_all(vari, "[^a-zA-ZáéíóúAÉÍÓÚ ]"));
return(dataf)
}
multifun(fecal.txt,"text")
multifun(fecal.txt,text)
multifun(fecal.txt, "text")
dataf <- mutate(dataf, vari = str_remove_all(vari, "[^a-zA-ZáéíóúAÉÍÓÚ ]"));
multifun <- function(dataf, vari){
dataf <- mutate(dataf, vari = str_remove_all(vari, "[^a-zA-ZáéíóúAÉÍÓÚ ]"));
return(dataf)
}
multifun(fecal.txt, "text")
multifun(fecal.txt, text)
?enquo
fnc = function(data, col) {
col = enquo(col)
data %>%
str_remove_all(!!col, "[^a-zA-ZáéíóúAÉÍÓÚ ]")
}
fnc(fecal.txt, text)
fnc = function(data, col) {
col = enquo(col)
data %>%
mutate(text = str_remove_all(!!col, "[^a-zA-ZáéíóúAÉÍÓÚ ]"))
}
fnc(fecal.txt, text)
fnc = function(data, col) {
col = enquo(col)
data %>%
mutate(holi = str_remove_all(!!col, "[^a-zA-ZáéíóúAÉÍÓÚ ]"))
}
fnc(fecal.txt, text)
fnc = function(data, col) {
col = enquo(col)
data %>%
mutate(text = str_replace_all(!!col, "\\n", " "),
text = str_remove_all(!!col, "[^a-zA-ZáéíóúAÉÍÓÚ ]"),
text = str_squish(!!col))
}
fnc(fecal.txt, text)
amlo_limpio <- amlo %>%
mutate(text = str_replace_all(text, "\\n", " "),
text = str_remove_all(text, "[^a-zA-ZáéíóúAÉÍÓÚñÑ ]"),
text = str_squish(text))
fecal_limpio <- fecal.txt %>%
mutate(text = str_replace_all(text, "\\n", " "),
text = str_remove_all(text, "[^a-zA-ZáéíóúAÉÍÓÚñÑ ]"),
text = str_squish(text))
getwd()
tokens <- detectives %>%
unnest_tokens(tokens, value) %>%
count(tokens) %>%
arrange(-n)
pacman::p_load(tidyverse,
gutenbergr,
readtext,
epubr,
here)
tokens <- detectives %>%
unnest_tokens(tokens, value) %>%
count(tokens) %>%
arrange(-n) %>%
filter(!tokens %in% tm::stopwords("es"))
pacman::p_load(tidyverse,
tidytext,
gutenbergr,
readtext,
epubr,
here)
amlo_tokens <- amlo_limpio %>%
unnest_tokens(tokens, value) %>%
count(tokens) %>%
arrange(-n) %>%
filter(!tokens %in% tm::stopwords("es"))
amlo_tokens <- amlo_limpio %>%
unnest_tokens(tokens, text) %>%
count(tokens) %>%
arrange(-n) %>%
filter(!tokens %in% tm::stopwords("es"))
amlo_tokens <- amlo_limpio %>%
unnest_tokens(tokens, text) %>%
count(tokens) %>%
arrange(-n) %>%
filter(!tokens %in% stopwords("es"))
pacman::p_load(tidyverse,
tidytext,
tm,
gutenbergr,
readtext,
epubr,
here)
amlo_tokens <- amlo_limpio %>%
unnest_tokens(tokens, text) %>%
count(tokens) %>%
arrange(-n) %>%
filter(!tokens %in% tm::stopwords("es"))
amlo_tokens
View(amlo_tokens)
amlo_limpio %>%
unnest_tokens(tokens, text)
amlo_limpio
amlo_limpio <- amlo %>%
mutate(text = str_replace_all(text, "\\n", " "),
text = str_remove_all(text, "[^a-zA-ZáéíóúAÉÍÓÚñÑ ]"),
text = str_squish(text))
amlo_limpio
amlo_limpio$text
?unnest_tokens
amlo_tokens <- amlo_limpio %>%
unnest_tokens(tokens, text, token = "sentences") %>%
count(tokens) %>%
arrange(-n) %>%
filter(!tokens %in% tm::stopwords("es"))
amlo_limpio %>%
unnest_tokens(tokens, text, token = "sentences")
amlo_tokens <- amlo_limpio %>%
unnest_tokens(tokens, text, token = "sentences")
View(amlo_tokens)
install.packages("tidytext")
pacman::p_load(tidyverse,
tidytext,
tm,
gutenbergr,
readtext,
epubr,
here)
class(amlo_limpio)
amlo_limpio <- amlo %>%
tibble() %>%
mutate(text = str_replace_all(text, "\\n", " "),
text = str_remove_all(text, "[^a-zA-ZáéíóúAÉÍÓÚñÑ ]"),
text = str_squish(text))
class(amlo_limpio)
fecal_limpio <- fecal.txt %>%
tibble() %>%
mutate(text = str_replace_all(text, "\\n", " "),
text = str_remove_all(text, "[^a-zA-ZáéíóúAÉÍÓÚñÑ ]"),
text = str_squish(text))
amlo_tokens <- amlo_limpio %>%
unnest_tokens(tokens, text, token = "sentences") %>%
count(tokens) %>%
arrange(-n) %>%
filter(!tokens %in% tm::stopwords("es"))
amlo_tokens
amlo_limpio <- amlo %>%
tibble() %>%
mutate(text = str_replace_all(text, "\\n", " "),
text = str_remove_all(text, "[^a-zA-ZáéíóúAÉÍÓÚñÑ., ]"),
text = str_squish(text))
amlo_tokens <- amlo_limpio %>%
unnest_tokens(tokens, text, token = "sentences")
View(amlo_tokens)
amlo_tokens <- amlo_limpio %>%
unnest_tokens(tokens, text) %>%
count(tokens) %>%
arrange(-n) %>%
filter(!tokens %in% tm::stopwords("es"))
View(amlo_tokens)
fecal_tokens <- fecal_limpio  %>%
unnest_tokens(tokens, text) %>%
count(tokens) %>%
arrange(-n) %>%
filter(!tokens %in% tm::stopwords("es"))
View(fecal_tokens)
enriquez_fuego <- epub("01_datos/literatura/Las cosas que perdimos en el fuego by Enríquez, Mariana (z-lib.org).epub")
enriquez_fuego <- fecal.txt %>%
tibble() %>%
mutate(text = str_replace_all(text, "\\n", " "),
text = str_remove_all(text, "[^a-zA-ZáéíóúAÉÍÓÚñÑ ]"),
text = str_squish(text))
enriquez_limpio <- enriquez_fuego %>%
tibble() %>%
mutate(text = str_replace_all(text, "\\n", " "),
text = str_remove_all(text, "[^a-zA-ZáéíóúAÉÍÓÚñÑ ]"),
text = str_squish(text))
enriquez_tokens <- enriquez_limpio %>%
unnest_tokens(tokens, text) %>%
count(tokens) %>%
arrange(-n) %>%
filter(!tokens %in% tm::stopwords("es"))
View(enriquez_tokens)
enriquez_limpio <- enriquez_fuego %>%
tibble() %>%
mutate(text = str_replace_all(text, "\\n", " "),
text = str_remove_all(text, "[^a-zA-ZáéíóúAÉÍÓÚñÑ ]"),
text = str_squish(text))
enriquez_tokens <- enriquez_limpio %>%
unnest_tokens(tokens, text) %>%
count(tokens) %>%
arrange(-n) %>%
filter(!tokens %in% tm::stopwords("es"))
View(enriquez_tokens)
enriquez_fuego <- epub("01_datos/literatura/Las cosas que perdimos en el fuego by Enríquez, Mariana (z-lib.org).epub")
enriquez_limpio <- enriquez_fuego %>%
tibble() %>%
mutate(text = str_replace_all(text, "\\n", " "),
text = str_remove_all(text, "[^a-zA-ZáéíóúAÉÍÓÚñÑ ]"),
text = str_squish(text))
enriquez_tokens <- enriquez_limpio %>%
unnest_tokens(tokens, text) %>%
count(tokens) %>%
arrange(-n) %>%
filter(!tokens %in% tm::stopwords("es"))
View(enriquez_tokens)
View(enriquez_fuego)
enriquez_fuego <- epub("01_datos/literatura/Las cosas que perdimos en el fuego by Enríquez, Mariana (z-lib.org).epub")
enriquez_limpio <- enriquez_fuego %>%
tibble() %>%
mutate(text = str_replace_all(text, "\\n", " "),
text = str_remove_all(text, "[^a-zA-ZáéíóúAÉÍÓÚñÑ ]"),
text = str_squish(text))
enriquez_limpio <- enriquez_fuego %>%
data[[1]]
enriquez_limpio <- enriquez_fuego %>%
select(data[[1]])
enriquez_limpio <- enriquez_fuego %>%
select(data)
View(enriquez_limpio)
View(enriquez_limpio[[1]][[1]])
enriquez_limpio <- enriquez_fuego %>%
unnest(data)
View(enriquez_limpio)
enriquez_limpio <- enriquez_fuego %>%
unnest(data) %>%
filter(section = str_detect(section, "Secc"))
enriquez_limpio <- enriquez_fuego %>%
unnest(data) %>%
filter(str_detect(section, "Secc"))
enriquez_fuego %>%
unnest(data)
enriquez_limpio <- enriquez_fuego %>%
unnest(data)
enriquez_limpio <- enriquez_fuego %>%
unnest(data) %>%
filter(str_detect(section, "Section"))
enriquez_limpio <- enriquez_fuego %>%
unnest(data) %>%
filter(str_detect(section, "Section")) %>%
tibble() %>%
mutate(text = str_replace_all(text, "\\n", " "),
text = str_remove_all(text, "[^a-zA-ZáéíóúAÉÍÓÚñÑ ]"),
text = str_squish(text))
enriquez_tokens <- enriquez_limpio %>%
unnest_tokens(tokens, text) %>%
count(tokens) %>%
arrange(-n) %>%
filter(!tokens %in% tm::stopwords("es"))
View(enriquez_tokens)
txt1 <- "Vine a Comala porque me dijeron que acá vivía mi padre,
un tal Pedro Páramo. Mi madre me lo dijo. Y yo le prometí que vendría a verlo
en cuanto ella muriera. Le apreté sus manos en señal de que lo haría, pues ella
estaba por morirse y yo en un plan de prometerlo todo. 'No dejes de ir a visitarlo
—me recomendó. Se llama de este modo y de este otro.
Estoy segura de que le dará gusto conocerte.'"
txt
txt1
text %>%
str_extract_all("\\S*? (?=(million|billion))", simplify = TRUE) %>%
str_trim()
pacman::p_load(tidyverse,
tidytext,
here)
text %>%
str_extract_all("\\S*? (?=(million|billion))", simplify = TRUE) %>%
str_trim()
txt3 %>%
str_extract_all("\\S*? (?=(million|billion))", simplify = TRUE) %>%
str_trim()
txt3 <- "Odebrecht has admitted to paying $29 million in bribes to public officials in Peru between 2005 and 2014 in exchange for $12.5 billion in contracts."
txt3 %>%
str_extract_all("\\S*? (?=(million|billion))", simplify = TRUE) %>%
str_trim()
str_view(txt1, 'C{2,3}?')
str_view(txt1, 'V')
str_view(txt1, 'V+')
str_view(txt3, '\d{4}')
str_view(txt3, '\\d{4}')
str_view(txt3, '\\d{,4}')
str_view(txt3, '\\d{1,4}')
str_view(txt3, '\\d{1,4}+')
str_view(txt3, '\\d{1,4}?')
str_view_all(txt3, '\\d{1,4}')
str_view_all(txt3, '\\d{1,4}|\\d{1,4}[.]\\d{1,4}')
str_view_all(txt3, '\\d{1,4}|\\d{1,4}[\\.]\\d{1,4}')
str_view_all(txt3, '\\d{1,4}|\\d{1,4}[\.]\\d{1,4}')
str_view_all(txt3, '\\d{1,4}|\\d{1,4}\\.\\d{1,4}')
str_view_all(txt3, '\\d{1,4}|\\d{1,4}?\\d{1,4}')
str_extract_all(txt3, '\\d{1,4}|\\d{1,4}?\\d{1,4}')
str_view(txt2, "(..)\\1", match = TRUE)
txt2 <- "Huehxolotl, huehcho huan totolin (Latintlahtolli: (Meleagris gallopavo)
huan caxtillantlahtolli guajolote nozo pavo), occe itoca palach ompa Cuextecapan,
ce cuextecatlahtolcopa palats. Huexolomeh ce tototl itechpahuic totolin icenyeliz.
Ce tototl motenehua huehxolotl nozo tecuantotolin chanti ompa Ixachitlan Mictlampan,
totolpixca ipan occequin tlacatiyan ompa centlacticpac, nouhqui occe totolin, itoca
xiuhcozcatotolin, ce tototl chanti ompa Yucatán tlalyacatl ihuan Petén cuauhtlah.
Tlacameh huehxolomeh tlacuah inaca ihuan itotoltehuan, inon totolin ca ica
macehualtlacatl itechcopa achtocahuitl quemeh tlapixcayotl ipan ichan. "
str_view(txt2, "(..)\\1", match = TRUE)
str_view(txt2, "(..)\\2", match = TRUE)
str_view(txt2, "(..)\\1", match = TRUE)
str_view(txt2, "(..)", match = TRUE)
str_view_all(txt2, "(..)", match = TRUE)
str_view(txt2, "(..)", match = TRUE)
str_view(txt2, "(..)(..)", match = TRUE)
str_view(txt2, "(..)(..)\\2", match = TRUE)
str_view(txt2, "(..)(..)\\2", match = TRUE)
str_view(txt2, "(..)(..)\\6", match = TRUE)
str_view(txt2, "(..)(..)\\4", match = TRUE)
str_view(txt2, "(..)(..)", match = TRUE)
str_view_all(txt2, "(..)(..)", match = TRUE)
str_view_all(txt3, "(..)(..)", match = TRUE)
str_view_all(txt3, "(..)", match = TRUE)
